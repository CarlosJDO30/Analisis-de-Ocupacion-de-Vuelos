{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_de_datos = \"travel.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aircrafts_data (datos_de_aeronaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  aircraft_code                                              model  range\n",
      "0           773    {\"en\": \"Boeing 777-300\", \"ru\": \"Боинг 777-300\"}  11100\n",
      "1           763    {\"en\": \"Boeing 767-300\", \"ru\": \"Боинг 767-300\"}   7900\n",
      "2           SU9  {\"en\": \"Sukhoi Superjet-100\", \"ru\": \"Сухой Суп...   3000\n",
      "3           320  {\"en\": \"Airbus A320-200\", \"ru\": \"Аэробус A320-...   5700\n",
      "4           321  {\"en\": \"Airbus A321-200\", \"ru\": \"Аэробус A321-...   5600\n",
      "5           319  {\"en\": \"Airbus A319-100\", \"ru\": \"Аэробус A319-...   6700\n",
      "6           733    {\"en\": \"Boeing 737-300\", \"ru\": \"Боинг 737-300\"}   4200\n",
      "7           CN1  {\"en\": \"Cessna 208 Caravan\", \"ru\": \"Сессна 208...   1200\n",
      "8           CR2  {\"en\": \"Bombardier CRJ-200\", \"ru\": \"Бомбардье ...   2700\n"
     ]
    }
   ],
   "source": [
    "#Conexion a base de datos\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'aircrafts_data'\n",
    "aircrafts_data = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM aircrafts_data;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Mostrar el contenido de la tabla 'aircrafts_data'\n",
    "print(aircrafts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  aircraft_code  range             model_en\n",
      "0           773  11100       Boeing 777-300\n",
      "1           763   7900       Boeing 767-300\n",
      "2           SU9   3000  Sukhoi Superjet-100\n",
      "3           320   5700      Airbus A320-200\n",
      "4           321   5600      Airbus A321-200\n",
      "5           319   6700      Airbus A319-100\n",
      "6           733   4200       Boeing 737-300\n",
      "7           CN1   1200   Cessna 208 Caravan\n",
      "8           CR2   2700   Bombardier CRJ-200\n"
     ]
    }
   ],
   "source": [
    "# Datos corregidos de la tabla\n",
    "data = {\n",
    "    'index': [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'aircraft_code': ['773', '763', 'SU9', '320', '321', '319', '733', 'CN1', 'CR2'],\n",
    "    'model': [\n",
    "        {\"en\": \"Boeing 777-300\"},\n",
    "        {\"en\": \"Boeing 767-300\"},\n",
    "        {\"en\": \"Sukhoi Superjet-100\"},\n",
    "        {\"en\": \"Airbus A320-200\"},\n",
    "        {\"en\": \"Airbus A321-200\"},\n",
    "        {\"en\": \"Airbus A319-100\"},\n",
    "        {\"en\": \"Boeing 737-300\"},\n",
    "        {\"en\": \"Cessna 208 Caravan\"},\n",
    "        {\"en\": \"Bombardier CRJ-200\"}\n",
    "    ],\n",
    "    'range': [11100, 7900, 3000, 5700, 5600, 6700, 4200, 1200, 2700]\n",
    "}\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Expandir la columna 'model' en una nueva columna 'model_en'\n",
    "df['model_en'] = df['model'].apply(lambda x: x['en'])\n",
    "\n",
    "# Eliminar la columna original 'model'\n",
    "df.drop(columns='model', inplace=True)\n",
    "\n",
    "aircrafts_df = df.drop(columns=['index'])\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "aircrafts_df.to_csv('aircrafts_data.csv', index=False)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(aircrafts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen general:\n",
      "               Valores Nulos  Valores Únicos  Total de Registros\n",
      "index                      0               9                   9\n",
      "aircraft_code              0               9                   9\n",
      "range                      0               9                   9\n",
      "model_en                   0               9                   9\n"
     ]
    }
   ],
   "source": [
    "# Resumen general de valores nulos y únicos por columna\n",
    "resumen = pd.DataFrame({\n",
    "    'Valores Nulos': df.isnull().sum(),\n",
    "    'Valores Únicos': df.nunique(),\n",
    "    'Total de Registros': len(df)\n",
    "})\n",
    "\n",
    "print(\"\\nResumen general:\")\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### airports_data (datos_de_aeropuertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nuevo DataFrame procesado:\n",
      "    airport_code                                       airport_name  \\\n",
      "0            YKS          {\"en\": \"Yakutsk Airport\", \"ru\": \"Якутск\"}   \n",
      "1            MJZ            {\"en\": \"Mirny Airport\", \"ru\": \"Мирный\"}   \n",
      "2            KHV  {\"en\": \"Khabarovsk-Novy Airport\", \"ru\": \"Хабар...   \n",
      "3            PKC        {\"en\": \"Yelizovo Airport\", \"ru\": \"Елизово\"}   \n",
      "4            UUS  {\"en\": \"Yuzhno-Sakhalinsk Airport\", \"ru\": \"Хом...   \n",
      "..           ...                                                ...   \n",
      "99           MMK       {\"en\": \"Murmansk Airport\", \"ru\": \"Мурманск\"}   \n",
      "100          ABA           {\"en\": \"Abakan Airport\", \"ru\": \"Абакан\"}   \n",
      "101          BAX         {\"en\": \"Barnaul Airport\", \"ru\": \"Барнаул\"}   \n",
      "102          AAQ  {\"en\": \"Anapa Vityazevo Airport\", \"ru\": \"Витяз...   \n",
      "103          CNN         {\"en\": \"Chulman Airport\", \"ru\": \"Чульман\"}   \n",
      "\n",
      "                                                  city          timezone  \\\n",
      "0                    {\"en\": \"Yakutsk\", \"ru\": \"Якутск\"}      Asia/Yakutsk   \n",
      "1                     {\"en\": \"Mirnyj\", \"ru\": \"Мирный\"}      Asia/Yakutsk   \n",
      "2              {\"en\": \"Khabarovsk\", \"ru\": \"Хабаровск\"}  Asia/Vladivostok   \n",
      "3    {\"en\": \"Petropavlovsk\", \"ru\": \"Петропавловск-К...    Asia/Kamchatka   \n",
      "4    {\"en\": \"Yuzhno-Sakhalinsk\", \"ru\": \"Южно-Сахали...     Asia/Sakhalin   \n",
      "..                                                 ...               ...   \n",
      "99                {\"en\": \"Murmansk\", \"ru\": \"Мурманск\"}     Europe/Moscow   \n",
      "100                   {\"en\": \"Abakan\", \"ru\": \"Абакан\"}  Asia/Krasnoyarsk   \n",
      "101                 {\"en\": \"Barnaul\", \"ru\": \"Барнаул\"}  Asia/Krasnoyarsk   \n",
      "102                     {\"en\": \"Anapa\", \"ru\": \"Анапа\"}     Europe/Moscow   \n",
      "103              {\"en\": \"Neryungri\", \"ru\": \"Нерюнгри\"}      Asia/Yakutsk   \n",
      "\n",
      "                longitude              latitude  \n",
      "0        (129.77099609375  62.0932998657226562)  \n",
      "1     (114.03900146484375   62.534698486328125)  \n",
      "2        (135.18800354004  48.5279998779300001)  \n",
      "3    (158.453994750976562  53.1679000854492188)  \n",
      "4    (142.718002319335938  46.8886985778808594)  \n",
      "..                    ...                   ...  \n",
      "99   (32.7508010864257812  68.7817001342773438)  \n",
      "100  (91.3850021362304688  53.7400016784667969)  \n",
      "101  (83.5384979248046875   53.363800048828125)  \n",
      "102  (37.3473014831539984   45.002101898192997)  \n",
      "103  (124.914001464839998  56.9138984680179973)  \n",
      "\n",
      "[104 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Conexión a la base de datos (ajustar la ruta de 'base_de_datos')\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener la tabla 'airports_data'\n",
    "datos_de_aeropuertos = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM airports_data;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Función para extraer el valor de la clave 'en' de un diccionario\n",
    "def extraer_en(valor):\n",
    "    if isinstance(valor, dict):\n",
    "        return valor.get('en', None)\n",
    "    return valor\n",
    "\n",
    "# Función para separar las coordenadas (latitud y longitud)\n",
    "def separar_coordenadas(coordenadas):\n",
    "    if isinstance(coordenadas, str):\n",
    "        coords = coordenadas.split(',')\n",
    "        if len(coords) == 2:\n",
    "            return pd.Series({'longitude': coords[0], 'latitude': coords[1]})\n",
    "    return pd.Series({'longitude': None, 'latitude': None})\n",
    "\n",
    "# Aplicar la extracción de 'en' en las columnas que contienen diccionarios\n",
    "datos_de_aeropuertos['airport_name'] = datos_de_aeropuertos['airport_name'].apply(extraer_en)\n",
    "datos_de_aeropuertos['city'] = datos_de_aeropuertos['city'].apply(extraer_en)\n",
    "\n",
    "# Aplicar la separación de coordenadas\n",
    "coordenadas_separadas = datos_de_aeropuertos['coordinates'].apply(separar_coordenadas)\n",
    "\n",
    "# Añadir las nuevas columnas al DataFrame original\n",
    "datos_de_aeropuertos = pd.concat([datos_de_aeropuertos, coordenadas_separadas], axis=1)\n",
    "\n",
    "# Eliminar la columna original de coordenadas si ya no es necesaria\n",
    "datos_de_aeropuertos.drop(columns=['coordinates'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(\"\\nNuevo DataFrame procesado:\")\n",
    "print(datos_de_aeropuertos)\n",
    "\n",
    "datos_de_aeropuertos.to_csv('airports_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos normalizados y guardados en 'airports_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "datos_de_aeropuertos = pd.read_csv('airports_data.csv')\n",
    "\n",
    "# Función para extraer el valor de la clave 'en' de un diccionario\n",
    "def extraer_en(valor):\n",
    "    if isinstance(valor, str) and valor.startswith(\"{\"):\n",
    "        try:\n",
    "            # Convertir la cadena de texto en un diccionario y obtener el valor 'en'\n",
    "            valor_dict = eval(valor)\n",
    "            return valor_dict.get('en', None)\n",
    "        except:\n",
    "            return valor\n",
    "    return valor\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar la extracción de 'en' en las columnas que contienen diccionarios\n",
    "datos_de_aeropuertos['airport_name'] = datos_de_aeropuertos['airport_name'].apply(extraer_en)\n",
    "datos_de_aeropuertos['city'] = datos_de_aeropuertos['city'].apply(extraer_en)\n",
    "\n",
    "datos_de_aeropuertos['longitude'] = datos_de_aeropuertos['longitude'].str.strip('(')\n",
    "datos_de_aeropuertos['latitude'] = datos_de_aeropuertos['latitude'].str.strip(')')\n",
    "\n",
    "# Guardar el DataFrame resultante en un nuevo archivo CSV\n",
    "datos_de_aeropuertos.to_csv('airports_data.csv', index=False)\n",
    "\n",
    "print(\"Datos normalizados y guardados en 'airports_data.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen general:\n",
      "              Valores Nulos  Valores Únicos  Total de Registros\n",
      "airport_code              0             104                 104\n",
      "airport_name              0             104                 104\n",
      "city                      0             101                 104\n",
      "timezone                  0              17                 104\n",
      "longitude                 0             104                 104\n",
      "latitude                  0             104                 104\n"
     ]
    }
   ],
   "source": [
    "# Resumen general de valores nulos y únicos por columna\n",
    "resumen = pd.DataFrame({\n",
    "    'Valores Nulos': datos_de_aeropuertos.isnull().sum(),\n",
    "    'Valores Únicos': datos_de_aeropuertos.nunique(),\n",
    "    'Total de Registros': len(datos_de_aeropuertos)\n",
    "})\n",
    "\n",
    "print(\"\\nResumen general:\")\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boarding_passes (tarjetas_de_embarque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'boarding_passes':\n",
      "            ticket_no  flight_id  boarding_no seat_no\n",
      "0       0005435212351      30625            1      2D\n",
      "1       0005435212386      30625            2      3G\n",
      "2       0005435212381      30625            3      4H\n",
      "3       0005432211370      30625            4      5D\n",
      "4       0005435212357      30625            5     11A\n",
      "...               ...        ...          ...     ...\n",
      "579681  0005434302871      19945           85     20F\n",
      "579682  0005432892791      19945           86     21C\n",
      "579683  0005434302869      19945           87     20E\n",
      "579684  0005432802476      19945           88     21F\n",
      "579685  0005432802482      19945           89     21E\n",
      "\n",
      "[579686 rows x 4 columns]\n",
      "\n",
      "Nuevo DataFrame copiado:\n",
      "            ticket_no  flight_id  boarding_no seat_no\n",
      "0       0005435212351      30625            1      2D\n",
      "1       0005435212386      30625            2      3G\n",
      "2       0005435212381      30625            3      4H\n",
      "3       0005432211370      30625            4      5D\n",
      "4       0005435212357      30625            5     11A\n",
      "...               ...        ...          ...     ...\n",
      "579681  0005434302871      19945           85     20F\n",
      "579682  0005432892791      19945           86     21C\n",
      "579683  0005434302869      19945           87     20E\n",
      "579684  0005432802476      19945           88     21F\n",
      "579685  0005432802482      19945           89     21E\n",
      "\n",
      "[579686 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'boarding_passes'\n",
    "boarding_passes = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM boarding_passes;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'boarding_passes'\n",
    "print(\"Contenido de la tabla 'boarding_passes':\")\n",
    "print(boarding_passes)\n",
    "\n",
    "# Crear un DataFrame vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for column in boarding_passes.columns:\n",
    "    df[column] = boarding_passes[column]\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "print(\"\\nNuevo DataFrame copiado:\")\n",
    "print(boarding_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "ticket_no      0\n",
      "flight_id      0\n",
      "boarding_no    0\n",
      "seat_no        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores nulos en cada columna\n",
    "valores_nulos = boarding_passes.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(valores_nulos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos por columna:\n",
      "ticket_no      238834\n",
      "flight_id       11518\n",
      "boarding_no       374\n",
      "seat_no           461\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores únicos en cada columna\n",
    "valores_unicos = boarding_passes.nunique()\n",
    "print(\"\\nValores únicos por columna:\")\n",
    "print(valores_unicos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame se ha guardado correctamente en 'boarding_passes.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame 'df' en un archivo CSV\n",
    "df.to_csv('boarding_passes.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame se ha guardado correctamente en 'boarding_passes.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bookings (reservas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'bookings':\n",
      "       book_ref               book_date  total_amount\n",
      "0        00000F  2017-07-05 03:12:00+03        265700\n",
      "1        000012  2017-07-14 09:02:00+03         37900\n",
      "2        000068  2017-08-15 14:27:00+03         18100\n",
      "3        000181  2017-08-10 13:28:00+03        131800\n",
      "4        0002D8  2017-08-07 21:40:00+03         23600\n",
      "...         ...                     ...           ...\n",
      "262783   FFFEF3  2017-07-17 07:23:00+03         56000\n",
      "262784   FFFF2C  2017-08-08 05:55:00+03         10800\n",
      "262785   FFFF43  2017-07-20 20:42:00+03         78500\n",
      "262786   FFFFA8  2017-08-08 04:45:00+03         28800\n",
      "262787   FFFFF7  2017-07-01 22:12:00+03         73600\n",
      "\n",
      "[262788 rows x 3 columns]\n",
      "\n",
      "Nuevo DataFrame copiado:\n",
      "       book_ref               book_date  total_amount\n",
      "0        00000F  2017-07-05 03:12:00+03        265700\n",
      "1        000012  2017-07-14 09:02:00+03         37900\n",
      "2        000068  2017-08-15 14:27:00+03         18100\n",
      "3        000181  2017-08-10 13:28:00+03        131800\n",
      "4        0002D8  2017-08-07 21:40:00+03         23600\n",
      "...         ...                     ...           ...\n",
      "262783   FFFEF3  2017-07-17 07:23:00+03         56000\n",
      "262784   FFFF2C  2017-08-08 05:55:00+03         10800\n",
      "262785   FFFF43  2017-07-20 20:42:00+03         78500\n",
      "262786   FFFFA8  2017-08-08 04:45:00+03         28800\n",
      "262787   FFFFF7  2017-07-01 22:12:00+03         73600\n",
      "\n",
      "[262788 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'bookings'\n",
    "reservas = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM bookings;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'bookings'\n",
    "print(\"Contenido de la tabla 'bookings':\")\n",
    "print(reservas)\n",
    "\n",
    "\n",
    "# Crear un DataFrame vacío\n",
    "df_reservas = pd.DataFrame()\n",
    "\n",
    "for column in reservas.columns:\n",
    "    df_reservas[column] = reservas[column]\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "print(\"\\nNuevo DataFrame copiado:\")\n",
    "print(df_reservas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna book_date:\n",
      "book_date\n",
      "03    262788\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para extraer el valor después del signo '+'\n",
    "def extract_timezone_offset(date_str):\n",
    "    if '+' in date_str:\n",
    "        return date_str.split('+')[1]  # Devuelve la parte después del '+'\n",
    "    return None  # En caso de que no haya '+', devuelve None\n",
    "\n",
    "# Contar los valores únicos\n",
    "for column in ['book_date']:\n",
    "    unique_offsets = df_reservas[column].apply(extract_timezone_offset).value_counts()\n",
    "    print(f\"Valores únicos en la columna {column}:\")\n",
    "    print(unique_offsets)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  book_date\n",
      "0       2017-07-05 03:12:00\n",
      "1       2017-07-14 09:02:00\n",
      "2       2017-08-15 14:27:00\n",
      "3       2017-08-10 13:28:00\n",
      "4       2017-08-07 21:40:00\n",
      "...                     ...\n",
      "262783  2017-07-17 07:23:00\n",
      "262784  2017-08-08 05:55:00\n",
      "262785  2017-07-20 20:42:00\n",
      "262786  2017-08-08 04:45:00\n",
      "262787  2017-07-01 22:12:00\n",
      "\n",
      "[262788 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Función para eliminar el offset (+03)\n",
    "def remove_timezone_offset(date_str):\n",
    "    if '+' in date_str:\n",
    "        return date_str.split('+')[0]  # Devuelve solo la parte antes del '+'\n",
    "    return date_str  # Si no tiene '+', devuelve el valor original\n",
    "\n",
    "# Aplicar la función a las columnas de fechas\n",
    "for column in ['book_date']:\n",
    "    df_reservas[column] = df_reservas[column].apply(remove_timezone_offset)\n",
    "\n",
    "# Ver el resultado\n",
    "print(df_reservas[['book_date']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book_ref            book_date  total_amount\n",
      "0        00000F  2017-07-05 03:12:00        265700\n",
      "1        000012  2017-07-14 09:02:00         37900\n",
      "2        000068  2017-08-15 14:27:00         18100\n",
      "3        000181  2017-08-10 13:28:00        131800\n",
      "4        0002D8  2017-08-07 21:40:00         23600\n",
      "...         ...                  ...           ...\n",
      "262783   FFFEF3  2017-07-17 07:23:00         56000\n",
      "262784   FFFF2C  2017-08-08 05:55:00         10800\n",
      "262785   FFFF43  2017-07-20 20:42:00         78500\n",
      "262786   FFFFA8  2017-08-08 04:45:00         28800\n",
      "262787   FFFFF7  2017-07-01 22:12:00         73600\n",
      "\n",
      "[262788 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verificar los nombres de las columnas en el DataFrame\n",
    "print(df_reservas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "book_ref        0\n",
      "book_date       0\n",
      "total_amount    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores nulos en cada columna\n",
    "valores_nulos_reservas = reservas.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(valores_nulos_reservas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos por columna:\n",
      "book_ref        262788\n",
      "book_date        68631\n",
      "total_amount      3926\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores únicos en cada columna\n",
    "valores_unicos_reservas = reservas.nunique()\n",
    "print(\"\\nValores únicos por columna:\")\n",
    "print(valores_unicos_reservas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame se ha guardado correctamente en 'bookings.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame 'df' en un archivo CSV\n",
    "df_reservas.to_csv('bookings.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame se ha guardado correctamente en 'bookings.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flights (vuelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'flights':\n",
      "       flight_id flight_no     scheduled_departure       scheduled_arrival  \\\n",
      "0           1185    PG0134  2017-09-10 09:50:00+03  2017-09-10 14:55:00+03   \n",
      "1           3979    PG0052  2017-08-25 14:50:00+03  2017-08-25 17:35:00+03   \n",
      "2           4739    PG0561  2017-09-05 12:30:00+03  2017-09-05 14:15:00+03   \n",
      "3           5502    PG0529  2017-09-12 09:50:00+03  2017-09-12 11:20:00+03   \n",
      "4           6938    PG0461  2017-09-04 12:25:00+03  2017-09-04 13:20:00+03   \n",
      "...          ...       ...                     ...                     ...   \n",
      "33116      33117    PG0063  2017-08-02 19:25:00+03  2017-08-02 20:10:00+03   \n",
      "33117      33118    PG0063  2017-07-28 19:25:00+03  2017-07-28 20:10:00+03   \n",
      "33118      33119    PG0063  2017-09-08 19:25:00+03  2017-09-08 20:10:00+03   \n",
      "33119      33120    PG0063  2017-08-01 19:25:00+03  2017-08-01 20:10:00+03   \n",
      "33120      33121    PG0063  2017-08-26 19:25:00+03  2017-08-26 20:10:00+03   \n",
      "\n",
      "      departure_airport arrival_airport     status aircraft_code  \\\n",
      "0                   DME             BTK  Scheduled           319   \n",
      "1                   VKO             HMA  Scheduled           CR2   \n",
      "2                   VKO             AER  Scheduled           763   \n",
      "3                   SVO             UFA  Scheduled           763   \n",
      "4                   SVO             ULV  Scheduled           SU9   \n",
      "...                 ...             ...        ...           ...   \n",
      "33116               SKX             SVO    Arrived           CR2   \n",
      "33117               SKX             SVO    Arrived           CR2   \n",
      "33118               SKX             SVO  Scheduled           CR2   \n",
      "33119               SKX             SVO    Arrived           CR2   \n",
      "33120               SKX             SVO  Scheduled           CR2   \n",
      "\n",
      "             actual_departure          actual_arrival  \n",
      "0                          \\N                      \\N  \n",
      "1                          \\N                      \\N  \n",
      "2                          \\N                      \\N  \n",
      "3                          \\N                      \\N  \n",
      "4                          \\N                      \\N  \n",
      "...                       ...                     ...  \n",
      "33116  2017-08-02 19:25:00+03  2017-08-02 20:10:00+03  \n",
      "33117  2017-07-28 19:30:00+03  2017-07-28 20:15:00+03  \n",
      "33118                      \\N                      \\N  \n",
      "33119  2017-08-01 19:26:00+03  2017-08-01 20:12:00+03  \n",
      "33120                      \\N                      \\N  \n",
      "\n",
      "[33121 rows x 10 columns]\n",
      "\n",
      "Nuevo DataFrame copiado:\n",
      "       flight_id flight_no     scheduled_departure       scheduled_arrival  \\\n",
      "0           1185    PG0134  2017-09-10 09:50:00+03  2017-09-10 14:55:00+03   \n",
      "1           3979    PG0052  2017-08-25 14:50:00+03  2017-08-25 17:35:00+03   \n",
      "2           4739    PG0561  2017-09-05 12:30:00+03  2017-09-05 14:15:00+03   \n",
      "3           5502    PG0529  2017-09-12 09:50:00+03  2017-09-12 11:20:00+03   \n",
      "4           6938    PG0461  2017-09-04 12:25:00+03  2017-09-04 13:20:00+03   \n",
      "...          ...       ...                     ...                     ...   \n",
      "33116      33117    PG0063  2017-08-02 19:25:00+03  2017-08-02 20:10:00+03   \n",
      "33117      33118    PG0063  2017-07-28 19:25:00+03  2017-07-28 20:10:00+03   \n",
      "33118      33119    PG0063  2017-09-08 19:25:00+03  2017-09-08 20:10:00+03   \n",
      "33119      33120    PG0063  2017-08-01 19:25:00+03  2017-08-01 20:10:00+03   \n",
      "33120      33121    PG0063  2017-08-26 19:25:00+03  2017-08-26 20:10:00+03   \n",
      "\n",
      "      departure_airport arrival_airport     status aircraft_code  \\\n",
      "0                   DME             BTK  Scheduled           319   \n",
      "1                   VKO             HMA  Scheduled           CR2   \n",
      "2                   VKO             AER  Scheduled           763   \n",
      "3                   SVO             UFA  Scheduled           763   \n",
      "4                   SVO             ULV  Scheduled           SU9   \n",
      "...                 ...             ...        ...           ...   \n",
      "33116               SKX             SVO    Arrived           CR2   \n",
      "33117               SKX             SVO    Arrived           CR2   \n",
      "33118               SKX             SVO  Scheduled           CR2   \n",
      "33119               SKX             SVO    Arrived           CR2   \n",
      "33120               SKX             SVO  Scheduled           CR2   \n",
      "\n",
      "             actual_departure          actual_arrival  \n",
      "0                          \\N                      \\N  \n",
      "1                          \\N                      \\N  \n",
      "2                          \\N                      \\N  \n",
      "3                          \\N                      \\N  \n",
      "4                          \\N                      \\N  \n",
      "...                       ...                     ...  \n",
      "33116  2017-08-02 19:25:00+03  2017-08-02 20:10:00+03  \n",
      "33117  2017-07-28 19:30:00+03  2017-07-28 20:15:00+03  \n",
      "33118                      \\N                      \\N  \n",
      "33119  2017-08-01 19:26:00+03  2017-08-01 20:12:00+03  \n",
      "33120                      \\N                      \\N  \n",
      "\n",
      "[33121 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'flights'\n",
    "vuelos = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM flights;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'flights'\n",
    "print(\"Contenido de la tabla 'flights':\")\n",
    "print(vuelos)\n",
    "\n",
    "# Si quieres recorrer los datos y crear un nuevo DataFrame a partir de las columnas de 'datos_de_aeropuertos'\n",
    "# Crear un DataFrame vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Recorrer las columnas del DataFrame 'datos_de_aeropuertos' y añadirlas a 'df'\n",
    "for column in vuelos.columns:\n",
    "    df[column] = vuelos[column]\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "print(\"\\nNuevo DataFrame copiado:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observaron muchos datos nulos en las columnas actual_departure y actual_arrival. Esos datos debian ser reemplazados ya que se referían a un hecho concreto.\n",
    "Se optó por reemplazar esos datos con los de las columnas scheduled_departure y scheduled_arrival correspondientemente. \n",
    " (Las columnas actual_departure y actual_arrival hacen referencia a la hora y el dia REAL que llegaron o partieron los aviones, y las columnas scheduled_departure y scheduled_arrival hacen referencia a lo que se tiene PROGRAMADO en cuanto a la salida y la llegada de esos vuelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reemplazar los valores \\N en actual_departure\n",
    "df['actual_departure'] = df['actual_departure'].replace('\\\\N', pd.NA)\n",
    "\n",
    "# Reemplazar los valores \\N en actual_arrival\n",
    "df['actual_arrival'] = df['actual_arrival'].replace('\\\\N', pd.NA)\n",
    "\n",
    "# Reemplazar los valores NA en actual_departure con los valores de scheduled_departure\n",
    "df['actual_departure'] = df['actual_departure'].combine_first(df['scheduled_departure'])\n",
    "\n",
    "# Reemplazar los valores NA en actual_arrival con los valores de scheduled_arrival\n",
    "df['actual_arrival'] = df['actual_arrival'].combine_first(df['scheduled_arrival'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       scheduled_departure    scheduled_arrival     actual_departure  \\\n",
      "0      2017-09-10 09:50:00  2017-09-10 14:55:00  2017-09-10 09:50:00   \n",
      "1      2017-08-25 14:50:00  2017-08-25 17:35:00  2017-08-25 14:50:00   \n",
      "2      2017-09-05 12:30:00  2017-09-05 14:15:00  2017-09-05 12:30:00   \n",
      "3      2017-09-12 09:50:00  2017-09-12 11:20:00  2017-09-12 09:50:00   \n",
      "4      2017-09-04 12:25:00  2017-09-04 13:20:00  2017-09-04 12:25:00   \n",
      "...                    ...                  ...                  ...   \n",
      "33116  2017-08-02 19:25:00  2017-08-02 20:10:00  2017-08-02 19:25:00   \n",
      "33117  2017-07-28 19:25:00  2017-07-28 20:10:00  2017-07-28 19:30:00   \n",
      "33118  2017-09-08 19:25:00  2017-09-08 20:10:00  2017-09-08 19:25:00   \n",
      "33119  2017-08-01 19:25:00  2017-08-01 20:10:00  2017-08-01 19:26:00   \n",
      "33120  2017-08-26 19:25:00  2017-08-26 20:10:00  2017-08-26 19:25:00   \n",
      "\n",
      "            actual_arrival  \n",
      "0      2017-09-10 14:55:00  \n",
      "1      2017-08-25 17:35:00  \n",
      "2      2017-09-05 14:15:00  \n",
      "3      2017-09-12 11:20:00  \n",
      "4      2017-09-04 13:20:00  \n",
      "...                    ...  \n",
      "33116  2017-08-02 20:10:00  \n",
      "33117  2017-07-28 20:15:00  \n",
      "33118  2017-09-08 20:10:00  \n",
      "33119  2017-08-01 20:12:00  \n",
      "33120  2017-08-26 20:10:00  \n",
      "\n",
      "[33121 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Función para eliminar el offset (+03)\n",
    "def remove_timezone_offset(date_str):\n",
    "    if '+' in date_str:\n",
    "        return date_str.split('+')[0]  # Devuelve solo la parte antes del '+'\n",
    "    return date_str  # Si no tiene '+', devuelve el valor original\n",
    "\n",
    "# Aplicar la función a las columnas de fechas\n",
    "for column in ['scheduled_departure', 'scheduled_arrival', 'actual_departure', 'actual_arrival']:\n",
    "    df[column] = df[column].apply(remove_timezone_offset)\n",
    "\n",
    "# Ver el resultado\n",
    "print(df[['scheduled_departure', 'scheduled_arrival', 'actual_departure', 'actual_arrival']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "flight_id              0\n",
      "flight_no              0\n",
      "scheduled_departure    0\n",
      "scheduled_arrival      0\n",
      "departure_airport      0\n",
      "arrival_airport        0\n",
      "status                 0\n",
      "aircraft_code          0\n",
      "actual_departure       0\n",
      "actual_arrival         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores nulos en cada columna\n",
    "valores_nulos_vuelos = vuelos.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(valores_nulos_vuelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos por columna:\n",
      "flight_id              33121\n",
      "flight_no                710\n",
      "scheduled_departure    10365\n",
      "scheduled_arrival       9648\n",
      "departure_airport        104\n",
      "arrival_airport          104\n",
      "status                     6\n",
      "aircraft_code              8\n",
      "actual_departure       17236\n",
      "actual_arrival         16636\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores únicos en cada columna\n",
    "valores_unicos_vuelos = df.nunique()\n",
    "print(\"\\nValores únicos por columna:\")\n",
    "print(valores_unicos_vuelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el archivo CSV modificado\n",
    "df.to_csv('flights.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seats (Asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'seats':\n",
      "    airport_code               airport_name               city  \\\n",
      "0            YKS            Yakutsk Airport            Yakutsk   \n",
      "1            MJZ              Mirny Airport             Mirnyj   \n",
      "2            KHV    Khabarovsk-Novy Airport         Khabarovsk   \n",
      "3            PKC           Yelizovo Airport      Petropavlovsk   \n",
      "4            UUS  Yuzhno-Sakhalinsk Airport  Yuzhno-Sakhalinsk   \n",
      "..           ...                        ...                ...   \n",
      "99           MMK           Murmansk Airport           Murmansk   \n",
      "100          ABA             Abakan Airport             Abakan   \n",
      "101          BAX            Barnaul Airport            Barnaul   \n",
      "102          AAQ    Anapa Vityazevo Airport              Anapa   \n",
      "103          CNN            Chulman Airport          Neryungri   \n",
      "\n",
      "             timezone            longitude             latitude  \n",
      "0        Asia/Yakutsk      129.77099609375  62.0932998657226562  \n",
      "1        Asia/Yakutsk   114.03900146484375   62.534698486328125  \n",
      "2    Asia/Vladivostok      135.18800354004  48.5279998779300001  \n",
      "3      Asia/Kamchatka  158.453994750976562  53.1679000854492188  \n",
      "4       Asia/Sakhalin  142.718002319335938  46.8886985778808594  \n",
      "..                ...                  ...                  ...  \n",
      "99      Europe/Moscow  32.7508010864257812  68.7817001342773438  \n",
      "100  Asia/Krasnoyarsk  91.3850021362304688  53.7400016784667969  \n",
      "101  Asia/Krasnoyarsk  83.5384979248046875   53.363800048828125  \n",
      "102     Europe/Moscow  37.3473014831539984   45.002101898192997  \n",
      "103      Asia/Yakutsk  124.914001464839998  56.9138984680179973  \n",
      "\n",
      "[104 rows x 6 columns]\n",
      "\n",
      "Nuevo DataFrame copiado:\n",
      "     aircraft_code seat_no fare_conditions\n",
      "0              319      2A        Business\n",
      "1              319      2C        Business\n",
      "2              319      2D        Business\n",
      "3              319      2F        Business\n",
      "4              319      3A        Business\n",
      "...            ...     ...             ...\n",
      "1334           773     48H         Economy\n",
      "1335           773     48K         Economy\n",
      "1336           773     49A         Economy\n",
      "1337           773     49C         Economy\n",
      "1338           773     49D         Economy\n",
      "\n",
      "[1339 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'seats'\n",
    "asientos = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM seats;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'seats'\n",
    "print(\"Contenido de la tabla 'seats':\")\n",
    "print(datos_de_aeropuertos)\n",
    "\n",
    "# Si quieres recorrer los datos y crear un nuevo DataFrame a partir de las columnas de 'datos_de_aeropuertos'\n",
    "# Crear un DataFrame vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Recorrer las columnas del DataFrame 'datos_de_aeropuertos' y añadirlas a 'df'\n",
    "for column in asientos.columns:\n",
    "    df[column] = asientos[column]\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "print(\"\\nNuevo DataFrame copiado:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "aircraft_code      0\n",
      "seat_no            0\n",
      "fare_conditions    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores nulos en cada columna\n",
    "valores_nulos_asientos = asientos.isnull().sum()\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(valores_nulos_asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos por columna:\n",
      "aircraft_code        9\n",
      "seat_no            461\n",
      "fare_conditions      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar el número de valores únicos en cada columna\n",
    "valores_unicos_asientos = asientos.nunique()\n",
    "print(\"\\nValores únicos por columna:\")\n",
    "print(valores_unicos_asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame se ha guardado correctamente en 'seats.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame 'df' en un archivo CSV\n",
    "df.to_csv('seats.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame se ha guardado correctamente en 'seats.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ticket_flights (boletos_de_Avion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'ticket_flights':\n",
      "             ticket_no  flight_id fare_conditions  amount\n",
      "0        0005432159776      30625        Business   42100\n",
      "1        0005435212351      30625        Business   42100\n",
      "2        0005435212386      30625        Business   42100\n",
      "3        0005435212381      30625        Business   42100\n",
      "4        0005432211370      30625        Business   42100\n",
      "...                ...        ...             ...     ...\n",
      "1045721  0005435097522      32094         Economy    5200\n",
      "1045722  0005435097521      32094         Economy    5200\n",
      "1045723  0005435104384      32094         Economy    5200\n",
      "1045724  0005435104352      32094         Economy    5200\n",
      "1045725  0005435104389      32094         Economy    5200\n",
      "\n",
      "[1045726 rows x 4 columns]\n",
      "\n",
      "Nuevo DataFrame copiado:\n",
      "             ticket_no  flight_id fare_conditions  amount\n",
      "0        0005432159776      30625        Business   42100\n",
      "1        0005435212351      30625        Business   42100\n",
      "2        0005435212386      30625        Business   42100\n",
      "3        0005435212381      30625        Business   42100\n",
      "4        0005432211370      30625        Business   42100\n",
      "...                ...        ...             ...     ...\n",
      "1045721  0005435097522      32094         Economy    5200\n",
      "1045722  0005435097521      32094         Economy    5200\n",
      "1045723  0005435104384      32094         Economy    5200\n",
      "1045724  0005435104352      32094         Economy    5200\n",
      "1045725  0005435104389      32094         Economy    5200\n",
      "\n",
      "[1045726 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener solo la tabla 'ticket_flights'\n",
    "boletos_de_avion = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM ticket_flights;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'seats'\n",
    "print(\"Contenido de la tabla 'ticket_flights':\")\n",
    "print(boletos_de_avion)\n",
    "\n",
    "# Si quieres recorrer los datos y crear un nuevo DataFrame a partir de las columnas de 'datos_de_aeropuertos'\n",
    "# Crear un DataFrame vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Recorrer las columnas del DataFrame 'datos_de_aeropuertos' y añadirlas a 'df'\n",
    "for column in boletos_de_avion.columns:\n",
    "    df[column] = boletos_de_avion[column]\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "print(\"\\nNuevo DataFrame copiado:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen general:\n",
      "                 Valores Nulos  Valores Únicos  Total de Registros\n",
      "ticket_no                    0          366733             1045726\n",
      "flight_id                    0           22226             1045726\n",
      "fare_conditions              0               3             1045726\n",
      "amount                       0             338             1045726\n"
     ]
    }
   ],
   "source": [
    "# Resumen general de valores nulos y únicos por columna\n",
    "resumen = pd.DataFrame({\n",
    "    'Valores Nulos': df.isnull().sum(),\n",
    "    'Valores Únicos': df.nunique(),\n",
    "    'Total de Registros': len(df)\n",
    "})\n",
    "\n",
    "print(\"\\nResumen general:\")\n",
    "print(resumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame se ha guardado correctamente en 'ticket_flights.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame 'df' en un archivo CSV\n",
    "df.to_csv('ticket_flights.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame se ha guardado correctamente en 'ticket_flights.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLA 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickets (Boletos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la tabla 'tickets':\n",
      "       ticket_no book_ref passenger_id\n",
      "0  0005432000987   06B046  8149 604011\n",
      "1  0005432000988   06B046  8499 420203\n",
      "2  0005432000989   E170C3  1011 752484\n",
      "3  0005432000990   E170C3  4849 400049\n",
      "4  0005432000991   F313DD  6615 976589\n",
      "\n",
      "El DataFrame se ha guardado correctamente en 'tickets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Conectar a la base de datos\n",
    "conn = sqlite3.connect(base_de_datos)\n",
    "\n",
    "# Consulta para obtener la tabla 'tickets'\n",
    "boletos = pd.read_sql(\"\"\"\n",
    "                            SELECT *\n",
    "                            FROM tickets;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Mostrar el contenido de la tabla 'tickets'\n",
    "print(\"Contenido de la tabla 'tickets':\")\n",
    "print(boletos.head())  # Mostrar las primeras filas para verificar los datos\n",
    "\n",
    "# Aquí el DataFrame 'boletos' ya está completo, no es necesario crear otro DataFrame vacío\n",
    "\n",
    "# Guardar el DataFrame 'boletos' en un archivo CSV (si es necesario)\n",
    "\n",
    "boletos.to_csv('tickets.csv', index=False)\n",
    "print(\"\\nEl DataFrame se ha guardado correctamente en 'tickets.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen general:\n",
      "              Valores Nulos  Valores Únicos  Total de Registros\n",
      "ticket_no                 0          366733              366733\n",
      "book_ref                  0          262788              366733\n",
      "passenger_id              0          366733              366733\n"
     ]
    }
   ],
   "source": [
    "# Resumen general de valores nulos y únicos por columna\n",
    "conteo = pd.DataFrame({\n",
    "    'Valores Nulos': boletos.isnull().sum(),\n",
    "    'Valores Únicos': boletos.nunique(),\n",
    "    'Total de Registros': len(boletos)\n",
    "})\n",
    "\n",
    "print(\"\\nResumen general:\")\n",
    "print(conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Columna: ticket_no\n",
      "Total de valores: 1045726\n",
      "Valores únicos: 366733\n",
      "----------------------------------------\n",
      "Columna: flight_id\n",
      "Total de valores: 1045726\n",
      "Valores únicos: 22226\n",
      "----------------------------------------\n",
      "Columna: fare_conditions\n",
      "Total de valores: 1045726\n",
      "Valores únicos: 3\n",
      "----------------------------------------\n",
      "Columna: amount\n",
      "Total de valores: 1045726\n",
      "Valores únicos: 338\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar las tablas desde CSV\n",
    "flights = pd.read_csv('flights.csv')\n",
    "aircrafts_data = pd.read_csv('aircrafts_data.csv')\n",
    "airports_data = pd.read_csv('airports_data.csv')\n",
    "boarding_passes = pd.read_csv('boarding_passes.csv')\n",
    "bookings = pd.read_csv('bookings.csv')\n",
    "tickets = pd.read_csv('tickets.csv')\n",
    "ticket_flights = pd.read_csv('ticket_flights.csv')\n",
    "seats = pd.read_csv('seats.csv')\n",
    "\n",
    "# Función para analizar todas las columnas de una tabla\n",
    "def analyze_all_columns(df):\n",
    "    print(\"=\" * 40)\n",
    "    for column in df.columns:\n",
    "        total_values = df[column].count()\n",
    "        unique_values = df[column].nunique()\n",
    "        print(f\"Columna: {column}\")\n",
    "        print(f\"Total de valores: {total_values}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        print(\"-\" * 40)\n",
    "# Análisis de todas las columnas de la tabla 'flights'\n",
    "\n",
    "analyze_all_columns(ticket_flights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Columna: ticket_no\n",
      "Total de valores: 366733\n",
      "Valores únicos: 366733\n",
      "----------------------------------------\n",
      "Columna: book_ref\n",
      "Total de valores: 366733\n",
      "Valores únicos: 262788\n",
      "----------------------------------------\n",
      "Columna: passenger_id\n",
      "Total de valores: 366733\n",
      "Valores únicos: 366733\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze_all_columns(df):\n",
    "    print(\"=\" * 40)\n",
    "    for column in df.columns:\n",
    "        total_values = df[column].count()\n",
    "        unique_values = df[column].nunique()\n",
    "        print(f\"Columna: {column}\")\n",
    "        print(f\"Total de valores: {total_values}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        print(\"-\" * 40)\n",
    "# Análisis de todas las columnas de la tabla 'flights'\n",
    "\n",
    "analyze_all_columns(tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Columna: ticket_no\n",
      "Total de valores: 579686\n",
      "Valores únicos: 238834\n",
      "----------------------------------------\n",
      "Columna: flight_id\n",
      "Total de valores: 579686\n",
      "Valores únicos: 11518\n",
      "----------------------------------------\n",
      "Columna: boarding_no\n",
      "Total de valores: 579686\n",
      "Valores únicos: 374\n",
      "----------------------------------------\n",
      "Columna: seat_no\n",
      "Total de valores: 579686\n",
      "Valores únicos: 461\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze_all_columns(df):\n",
    "    print(\"=\" * 40)\n",
    "    for column in df.columns:\n",
    "        total_values = df[column].count()\n",
    "        unique_values = df[column].nunique()\n",
    "        print(f\"Columna: {column}\")\n",
    "        print(f\"Total de valores: {total_values}\")\n",
    "        print(f\"Valores únicos: {unique_values}\")\n",
    "        print(\"-\" * 40)\n",
    "# Análisis de todas las columnas de la tabla 'flights'\n",
    "\n",
    "analyze_all_columns(boarding_passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado de columnas primary key en las tablas que lo requieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_identity_column(file_path, id_column_name):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Crear una columna autogenerada simulada\n",
    "    df[id_column_name] = range(1, len(df) + 1)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Ejemplo de uso\n",
    "add_identity_column('seats.csv', 'seat_id')\n",
    "add_identity_column('boarding_passes.csv', 'bp_id')\n",
    "add_identity_column('ticket_flights.csv', 'ticket_flights_id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
